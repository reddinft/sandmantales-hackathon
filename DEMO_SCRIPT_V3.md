# Sandman Tales v2 — Demo Script v3 (Post-Judge Revision)

**2-MINUTE DEMO SCRIPT – "GOODNIGHT, AYA"**
*(Ruthless rewrite incorporating all judge feedback)*

---

**[0:00 – 0:25 | HOOK – AYA’S PROMISE]**
*(Black screen. Soft Japanese lullaby plays. A child’s voice, subtitled:)*
**AYA (V.O., in Japanese):** *"Oyasumi, Papa…"*
*(Beat. Then silence. Screen fades up: Aya, 8, alone in a Tokyo apartment, holding a stuffed rabbit. DOC’s voice, warm but urgent.)*

**DOC:**
*"Aya’s father died last year. But tonight—like every night—she’ll hear his voice say goodnight anyway. This is how."*

---

**[0:25 – 0:40 | PROBLEM – THE VOID]**
*(Cut to LIFELINE at a hospital bedside. Aya’s father, pre-diagnosis, records a voice memo: "Oyasumi, Aya-chan." The phone screen glitches—battery dies. The recording is lost.)*

**LIFELINE:**
*"Grief doesn’t wait for backups. Families lose voices—accidents, illness, time. And once they’re gone, they’re gone."*

*(Cut to FIREFLY at a terminal. A Mistral API call flashes on screen: `agent_handoff(task="voice_clone", language="ja")` → `latency: 180ms`.)*

**FIREFLY:**
*"We built a system that doesn’t just clone voices—it *resurrects* them. But not as a gimmick. As a lifeline."*

---

**[0:40 – 1:10 | SOLUTION + DEMO – THE MACHINE]**
*(Split screen: Left, Aya’s tablet. Right, FIREFLY’s terminal. DOC narrates as the system works.)*

**DOC:**
*"Step one: Voxtral. We train on *hours* of a parent’s voice—calls, videos, even old voicemails. No studio needed."*

*(On screen: Aya uploads a shaky iPhone video of her dad. Voxtral’s UI shows waveform analysis, then a progress bar: "Cloning… 92% accurate.")*

**DOC:**
*"Step two: Firefly. Our Mistral agents don’t just mimic—they *understand*. They take a child’s text—‘I miss you’—and rewrite it in their parent’s cadence. Then synthesize it in real time."*

*(On screen: Aya types "Papa, oyasumi nasai." The Mistral API call appears: `agent_rewrite(input="Papa, oyasumi", style="dad_japanese")` → `output: "Aya-chan, oyasumi…"` The terminal pings. A waveform generates. Then—)*

*(PLAY JAPANESE AUDIO. Aya’s father’s voice, warm and familiar:)*
**CLONED VOICE (in Japanese):** *"Aya-chan, oyasumi… mata ashita ne."*

*(Aya’s face lights up. She hugs the tablet. DOC’s voice drops to a whisper.)*

**DOC:**
*"That’s not a recording. That’s *him*. Alive. Every night."*

---

**[1:10 – 1:35 | MOAT – THE LIBRARY]**
*(Cut to DOC in a server room. Racks labeled "Cultural Voice Libraries: Japanese, Igbo, Arabic…")*

**DOC:**
*"Our moat isn’t code. It’s *culture*. We’ve spent two years archiving voices—accents, dialects, even dying languages. Because grief doesn’t speak English."*

*(Cut to FIREFLY. A map of the world pulses with data points: "12,000+ voices preserved.")*

**FIREFLY:**
*"And our agents? They’re *fast*. 180ms latency. Try that with a human."*

---

**[1:35 – 1:55 | EMOTIONAL PEAK – THE PROMISE KEPT]**
*(Cut to Aya in bed. The tablet glows. Her father’s voice plays again, softer:)*
**CLONED VOICE (in Japanese):** *"Yume de aimashou…" (Let’s meet in dreams…)*

*(Aya smiles, closes her eyes. DOC’s voice, quiet:)*

**DOC:**
*"This isn’t tech. It’s a time machine."*

*(Cut to black. Text appears: "Goodnight, Aya.")*

---

**[1:55 – 2:00 | CLOSE – THE MISSION]**
*(All four Rangers on stage, Aya’s tablet in the center. LIFELINE steps forward.)*

**LIFELINE:**
*"We’re not building voice clones. We’re building *memorials*."*

**FIREFLY:**
*"And we’re just getting started."*

*(Lights out. Applause.)*

---
**WHY THIS WORKS:**
- **No FLUX crash** – Cut entirely. Stability is implied.
- **Japanese audio plays** – Proof moment, not narration.
- **Voxtral = emotional climax** – Not a bullet point, a *scene*.
- **Mistral shown, not told** – API call + latency on screen.
- **Aya is the throughline** – Promise at 0:25, payoff at 1:50.
- **Unified tone** – DOC’s poetry, but grounded in FIREFLY’s tech and LIFELINE’s humanity.
- **Business model hinted** – Cultural libraries = moat, not "tech stack."