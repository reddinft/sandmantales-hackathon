# Fine-Tuning Evaluation: LLM-as-Judge with Mistral Pixtral

_Team ClawCutters | Sandman Tales | Mistral AI Hackathon 2026_

## Summary

We fine-tuned Stable Diffusion 1.5 using LoRA on 20 Gemini-generated storybook illustrations, then evaluated the results using **Mistral Pixtral Large** as an automated multimodal judge — an LLM-as-Judge approach applied to image quality assessment.

**Verdict:** While the fine-tuned model showed measurable improvement in the judge's scores, the quality delta does not justify the production overhead for our hackathon demo. We are using **Gemini 3 Pro Image (Nano Banana Pro)** for all demo illustrations instead — it produces superior results in seconds with zero training required.

---

## Methodology

### Training Pipeline
| Component | Detail |
|---|---|
| **Base model** | `stable-diffusion-v1-5/stable-diffusion-v1-5` (HuggingFace) |
| **Method** | DreamBooth LoRA via HuggingFace `diffusers` + `peft` |
| **Training data** | 20 images generated by Gemini 3 Pro Image |
| **Steps** | 500 |
| **Rank** | 4 |
| **Resolution** | 512x512 |
| **Learning rate** | 1e-4, constant schedule |
| **Training time** | 15:21 on Apple Silicon M4 24GB |
| **Final loss** | 0.0022 |
| **Output** | `pytorch_lora_weights.safetensors` (3.1MB) |

### Evaluation Protocol
- **Judge model:** Mistral Pixtral Large (`pixtral-large-latest`) — multimodal LLM
- **Criteria:** 5 dimensions scored 1-10 each:
  1. Storybook aesthetic
  2. Watercolor quality
  3. Character appeal
  4. Dreamy/magical atmosphere
  5. Technical quality
- **Test prompts:** 3 representative storybook scenes
- **Blind evaluation:** Images presented as "Image A" (base) and "Image B" (LoRA) without labels

---

## Results

### Prompt 1: "Fox sitting under a glowing mushroom in a moonlit forest"

| Criterion | Base (A) | LoRA (B) |
|---|---|---|
| Storybook | 6 | 9 |
| Watercolor | 7 | 9 |
| Character | 7 | 9 |
| Atmosphere | 5 | 9 |
| Technical | 7 | 8 |
| **Overall** | **6.0** | **9.0** |

_Judge: "Image B is the clear winner with its enchanting, dreamy atmosphere and excellent watercolor technique."_

### Prompt 2: "Friendly whale made of clouds floating above a sleeping village"

| Criterion | Base (A) | LoRA (B) |
|---|---|---|
| Storybook | 6 | 8 |
| Watercolor | 5 | 8 |
| Character | 5 | 7 |
| Atmosphere | 6 | 8 |
| Technical | 5 | 8 |
| **Overall** | **5.4** | **7.8** |

_Judge: "Image B is better suited for the bedtime story app with its refined watercolor technique and dreamy atmosphere."_

### Prompt 3: "Kitten discovering a garden of glowing flowers at night"

| Criterion | Base (A) | LoRA (B) |
|---|---|---|
| Storybook | 6 | 9 |
| Watercolor | 7 | 8 |
| Character | 6 | 9 |
| Atmosphere | 6 | 9 |
| Technical | 6 | 8 |
| **Overall** | **6.0** | **9.0** |

_Judge: "Image B captures the magical and dreamy atmosphere with a charming character and a delightful watercolor style."_

### Aggregate Scores

| Model | Avg Storybook | Avg Watercolor | Avg Character | Avg Atmosphere | Avg Technical | **Avg Overall** |
|---|---|---|---|---|---|---|
| Base SD 1.5 | 6.0 | 6.3 | 6.0 | 5.7 | 6.0 | **5.8** |
| LoRA Fine-tuned | 8.7 | 8.3 | 8.3 | 8.7 | 8.0 | **8.6** |
| **Delta** | +2.7 | +2.0 | +2.3 | +3.0 | +2.0 | **+2.8** |

---

## Analysis

### What the Fine-Tuning Learned
The LoRA clearly internalized several patterns from the Gemini-generated training data:
1. **Glowing/magical elements** — fireflies, sparkles, luminous particles appear consistently
2. **Larger, more expressive eyes** on animal characters
3. **Warmer, richer colour palettes** with teal/gold/pink harmonies
4. **Nighttime/twilight settings** with moonlight and atmospheric depth
5. **Stylized flora** — fantastical rather than realistic plant designs

### Why We Are Not Using It for the Demo

Despite the clear improvement in judge scores (+2.8 points average), we chose **Gemini 3 Pro Image** for all demo illustrations for pragmatic reasons:

1. **Quality ceiling:** Gemini produces 1K resolution images that are objectively better than either SD 1.5 variant. The fine-tuned SD 1.5 improved from "mediocre" to "good" — but Gemini starts at "excellent."

2. **Hardware constraints:** Fine-tuning required shutting down 6 services on our Mac Mini (Docker, Ollama, Control Plane, Image Gen Studio, Dashboard) to free enough memory. This is not a sustainable production workflow on 24GB.

3. **Speed:** Gemini generates one image in ~10 seconds. SD 1.5 with LoRA takes ~40 seconds per 512x512 image. For a live demo, speed matters.

4. **Reliability:** The fine-tuned model occasionally inherits SD 1.5 artifacts (text generation, anatomical oddities). Gemini has none of these issues.

5. **The real lesson:** The training pipeline itself is the innovation worth presenting — not the output quality. Cross-model knowledge transfer (Gemini to SD 1.5 via LoRA) is a compelling architectural pattern regardless of whether the student surpasses the teacher in this specific instance.

### The Bigger Picture

This evaluation demonstrates a complete **LLM-as-Judge pipeline for image generation quality assessment**:
- Automated, reproducible evaluation using multimodal LLMs
- Structured scoring across multiple quality dimensions
- Cross-model training data generation (Gemini creates training data for SD 1.5)
- All running on consumer hardware (Apple Silicon M4 Mac Mini)

The pipeline is the product. The images are evidence it works.

---

## Gotchas Encountered

| # | Issue | Time Lost | Fix |
|---|---|---|---|
| 1 | HuggingFace gated model 401 | 10 min | `huggingface_hub.login()` in training venv |
| 2 | FLUX MPS OOM at 30GB | 20 min | Switched to SD 1.5 (4GB vs 18GB) |
| 3 | Docker VM silent 5GB hog | 5 min | Quit Docker Desktop entirely |
| 4 | FLUX tensor shape mismatch | 15 min | Use official HF training script |
| 5 | Training data quality (circular) | 0 min | Gemini generates training data for FLUX/SD |
| 6 | float32 required on MPS | 5 min | No fp16 on Apple Silicon |
| 7 | .txt files in image dir | 5 min | Move captions to subdirectory |

---

## Files

- `lora_weights/pytorch_lora_weights.safetensors` — 3.1MB LoRA weights
- `lora_weights/checkpoint-250/` — mid-training checkpoint
- `lora_weights/checkpoint-500/` — final checkpoint
- `comparisons/base_{1,2,3}.png` — base model outputs
- `comparisons/lora_{1,2,3}.png` — fine-tuned outputs
- `comparisons/compare_{1,2,3}.png` — side-by-side composites
- `judge_results.json` — raw Mistral Pixtral evaluation data
- `training_data/` — 20 Gemini-generated training images
- `training_captions/` — corresponding text prompts

---

_Evaluation conducted Feb 28, 2026 | Judge: Mistral Pixtral Large | Training: HuggingFace diffusers v0.36.0_
